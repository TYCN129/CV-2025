{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28\n",
    "LATENT_DIM = 16\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Loading and Preprocessing\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.CenterCrop(178),  # Crop center to remove background\n",
    "#     transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.5], [0.5])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "# path = kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# indices = torch.randperm(162770)[:80000] # 80k subset of training image indices\n",
    "\n",
    "# dataset = datasets.ImageFolder(root=path, transform=transform)\n",
    "# dataset = Subset(dataset, indices)  # Create subset of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:56<00:00, 177kB/s] \n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 62.0kB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset Loading with Train/Validation Split\u001b[39;00m\n\u001b[32m      2\u001b[39m transform = transforms.ToTensor()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m full_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m train_len = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.9\u001b[39m * \u001b[38;5;28mlen\u001b[39m(full_dataset))\n\u001b[32m      5\u001b[39m val_len = \u001b[38;5;28mlen\u001b[39m(full_dataset) - train_len\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:100\u001b[39m, in \u001b[36mMNIST.__init__\u001b[39m\u001b[34m(self, root, train, transform, target_transform, download)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:188\u001b[39m, in \u001b[36mMNIST.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    190\u001b[39m     errors.append(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/site-packages/torchvision/datasets/utils.py:391\u001b[39m, in \u001b[36mdownload_and_extract_archive\u001b[39m\u001b[34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[32m    389\u001b[39m     filename = os.path.basename(url)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m archive = os.path.join(download_root, filename)\n\u001b[32m    394\u001b[39m extract_archive(archive, extract_root, remove_finished)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/site-packages/torchvision/datasets/utils.py:130\u001b[39m, in \u001b[36mdownload_url\u001b[39m\u001b[34m(url, root, filename, md5, max_redirect_hops)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# download the file\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib.error.URLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[32m5\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/site-packages/torchvision/datasets/utils.py:28\u001b[39m, in \u001b[36m_urlretrieve\u001b[39m\u001b[34m(url, filename, chunk_size)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: Union[\u001b[38;5;28mstr\u001b[39m, pathlib.Path], chunk_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m1024\u001b[39m * \u001b[32m32\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUser-Agent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSER_AGENT\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total=response.length, unit=\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, unit_scale=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m     30\u001b[39m             \u001b[38;5;28;01mwhile\u001b[39;00m chunk := response.read(chunk_size):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/urllib/request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/urllib/request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/urllib/request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/urllib/request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     r = \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1350\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlenv/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Dataset Loading with Train/Validation Split\n",
    "transform = transforms.ToTensor()\n",
    "full_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_len = int(0.9 * len(full_dataset))\n",
    "val_len = len(full_dataset) - train_len\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_len, val_len])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(1024 * 4 * 4, LATENT_DIM)\n",
    "        self.fc_logvar = nn.Linear(1024 * 4 * 4, LATENT_DIM)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc_decode = nn.Linear(LATENT_DIM, 1024 * 4 * 4)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x).view(x.size(0), -1)\n",
    "        mu, logvar = self.fc_mu(x), self.fc_logvar(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        x_recon = self.decoder(self.fc_decode(z).view(z.size(0), 1024, 4, 4))\n",
    "        return x_recon\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_vae(vae_model, epochs=5, learning_rate=1e-3, batch_size=32):\n",
    "    vae_model.to(device)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(vae_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    vae_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for images, _ in progress_bar:\n",
    "            images = images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_images, mu, logvar = vae_model(images)\n",
    "            loss = vae_loss_function(recon_images, images, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=total_loss/len(dataloader.dataset))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(vae_model.state_dict(), \"vae_celebA.pth\")\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vae(vae, batch_size=64, epochs=10)\n",
    "# vae.load_state_dict(torch.load('vae_celebA.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_latent_vectors(dataset):\n",
    "    vae.to(device)\n",
    "    vae.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    latent_vectors = []\n",
    "    total_samples = len(dataset)  # Total number of images\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Extracting Latent Vectors\", unit=\"batch\")\n",
    "        for images, _ in progress_bar:\n",
    "            images = images.to(device)\n",
    "            z, _, _ = vae.encode(images)\n",
    "            latent_vectors.append(z.cpu().numpy())\n",
    "            \n",
    "            # Update progress description\n",
    "            progress_bar.set_postfix(processed=len(latent_vectors) * dataloader.batch_size, total=total_samples)\n",
    "\n",
    "    latent_vectors = np.concatenate(latent_vectors, axis=0)\n",
    "    return latent_vectors\n",
    "\n",
    "def get_pca_components(data, n_components=5):\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(data)\n",
    "    return pca.components_\n",
    "\n",
    "def get_z_pair(principal_vec, n=5, epsilon=2.0):\n",
    "    z_pairs = []\n",
    "\n",
    "    principal_vec = torch.tensor(principal_vec, dtype=torch.float32, device=device)\n",
    "\n",
    "    for _ in range(n):\n",
    "        z = torch.randn(1, LATENT_DIM, device=device)\n",
    "        z_modified = z + epsilon * principal_vec\n",
    "\n",
    "        z_pairs.append((z, z_modified))\n",
    "\n",
    "    z_originals, z_modifieds = zip(*z_pairs)\n",
    "    return torch.stack(z_originals), torch.stack(z_modifieds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = get_latent_vectors(dataset)\n",
    "principal_components = get_pca_components(latent_vectors, n_components=15)\n",
    "print(\"PCA fit done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image_pairs(img_original, img_modified, title=\"Original vs Modified\"):\n",
    "    assert len(img_original) == len(img_modified), \"Both lists must have the same length!\"\n",
    "    \n",
    "    num_images = len(img_original)\n",
    "    fig, axes = plt.subplots(num_images, 2, figsize=(6, 3 * num_images))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        original = img_original[i].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "        modified = img_modified[i].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        axes[i][0].imshow(original)\n",
    "        axes[i][0].set_title(\"Original\")\n",
    "        axes[i][0].axis(\"off\")\n",
    "        \n",
    "        axes[i][1].imshow(modified)\n",
    "        axes[i][1].set_title(\"Modified\")\n",
    "        axes[i][1].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prin_comp_idx = 2\n",
    "assert(prin_comp_idx < len(principal_components))\n",
    "z, z_modified = get_z_pair(principal_components[prin_comp_idx], epsilon=7.0, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vae.eval()\n",
    "    img_original = vae.decode(z).cpu().detach()\n",
    "    img_modified = vae.decode(z_modified).cpu().detach()\n",
    "\n",
    "# Scale from [-1, 1] → [0, 1]\n",
    "img_original = (img_original + 1) / 2\n",
    "img_modified = (img_modified + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_pairs(img_original, img_modified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
